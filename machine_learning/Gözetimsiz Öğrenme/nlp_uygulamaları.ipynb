{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5133e3e1-671e-472e-8896-af59ab6a1147",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NLP Uygulamaları"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c4a791-2a9c-46e2-8447-75a9206651e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9966965e-14a9-458a-a335-d10ed511473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d872f83-da85-42b0-8615-bcbb8aa7648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f430322-9442-4262-9ac4-b70bcc3ca58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f0144cd-db66-4b20-a60d-a96c7c5292bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\"Bu örneği anlaşılabilmesi için daha uzun bir metin üzerinden göstereceğim.\n",
    "N-gram'lar birlikte kullanılan kelimelerin kombinasyolarını gösterir\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "027f9bcc-215c-43eb-b4ea-9c3a3aa7c223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Bu', 'örneği', 'anlaşılabilmesi']),\n",
       " WordList(['örneği', 'anlaşılabilmesi', 'için']),\n",
       " WordList(['anlaşılabilmesi', 'için', 'daha']),\n",
       " WordList(['için', 'daha', 'uzun']),\n",
       " WordList(['daha', 'uzun', 'bir']),\n",
       " WordList(['uzun', 'bir', 'metin']),\n",
       " WordList(['bir', 'metin', 'üzerinden']),\n",
       " WordList(['metin', 'üzerinden', 'göstereceğim']),\n",
       " WordList(['üzerinden', 'göstereceğim', \"N-gram'lar\"]),\n",
       " WordList(['göstereceğim', \"N-gram'lar\", 'birlikte']),\n",
       " WordList([\"N-gram'lar\", 'birlikte', 'kullanılan']),\n",
       " WordList(['birlikte', 'kullanılan', 'kelimelerin']),\n",
       " WordList(['kullanılan', 'kelimelerin', 'kombinasyolarını']),\n",
       " WordList(['kelimelerin', 'kombinasyolarını', 'gösterir'])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(a).ngrams(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5279e2da-f918-4acc-9a93-9c5920e7e641",
   "metadata": {},
   "source": [
    "## Part of speech tagging (POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1de00cfd-7c8d-4821-98b7-c8b46f06fb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "801ab20f-3518-493f-a1bf-4348c5ad6684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sametsengun/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a47ba4d-bb78-47d0-999b-66aeefde4746",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metin = \"\"\"\n",
    "A Scandal in Bohemia! 01\n",
    "The Red-headed League,2\n",
    "A Case, of Identity 33\n",
    "The Boscombe Valley Mystery4\n",
    "The Five Orange Pips1\n",
    "The Man with? the Twisted Lip\n",
    "The Adventure of the Blue Carbuncle\n",
    "The Adventure of the Speckled Band\n",
    "The Adventure of the Engineer's Thumb\n",
    "The Adventure of the Noble Bachelor\n",
    "The Adventure of the Beryl Coronet\n",
    "The Adventure of the Copper Beeches\"\"\"\n",
    "\n",
    "metin\n",
    "v_metin = metin.split(\"\\n\")\n",
    "v = pd.Series(v_metin)\n",
    "metin_vektoru = v[1:len(v)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9acd9169-3d5b-495c-91c4-04c92697028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = pd.DataFrame(metin_vektoru, columns = [\"hikayeler\"])\n",
    "d_mdf = mdf.copy()\n",
    "d_mdf = d_mdf[\"hikayeler\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "d_mdf = d_mdf.str.replace(\"[^\\w\\s]\",\"\")\n",
    "d_mdf = d_mdf.str.replace(\"\\d\",\"\")\n",
    "d_mdf = pd.DataFrame(d_mdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "230bbe41-e2ac-4861-8089-65544855039e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'DT'), ('redheaded', 'JJ'), ('league', 'NN')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(d_mdf[\"hikayeler\"][2]).tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f31d857-218c-4bcf-b901-b3de2b2d1354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     [(a, DT), (scandal, NN), (in, IN), (bohemia, NN)]\n",
       "2            [(the, DT), (redheaded, JJ), (league, NN)]\n",
       "3       [(a, DT), (case, NN), (of, IN), (identity, NN)]\n",
       "4     [(the, DT), (boscombe, NN), (valley, NN), (mys...\n",
       "5     [(the, DT), (five, CD), (orange, NN), (pips, N...\n",
       "6     [(the, DT), (man, NN), (with, IN), (the, DT), ...\n",
       "7     [(the, DT), (adventure, NN), (of, IN), (the, D...\n",
       "8     [(the, DT), (adventure, NN), (of, IN), (the, D...\n",
       "9     [(the, DT), (adventure, NN), (of, IN), (the, D...\n",
       "10    [(the, DT), (adventure, NN), (of, IN), (the, D...\n",
       "11    [(the, DT), (adventure, NN), (of, IN), (the, D...\n",
       "12    [(the, DT), (adventure, NN), (of, IN), (the, D...\n",
       "Name: hikayeler, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_mdf[\"hikayeler\"].apply(lambda x: TextBlob(x).tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e71561-2809-455c-b4ab-5a436c9a2575",
   "metadata": {},
   "source": [
    "## Chunking (shallow parsing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5465256f-dc1e-44b1-aa16-2d0e26352e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = d_mdf[\"hikayeler\"].apply(lambda x: TextBlob(x).tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e66ad0ad-53f0-43fa-b17d-9e334510344c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     [(a, DT), (scandal, NN), (in, IN), (bohemia, NN)]\n",
       "2            [(the, DT), (redheaded, JJ), (league, NN)]\n",
       "3       [(a, DT), (case, NN), (of, IN), (identity, NN)]\n",
       "4     [(the, DT), (boscombe, NN), (valley, NN), (mys...\n",
       "5     [(the, DT), (five, CD), (orange, NN), (pips, N...\n",
       "6     [(the, DT), (man, NN), (with, IN), (the, DT), ...\n",
       "7     [(the, DT), (adventure, NN), (of, IN), (the, D...\n",
       "8     [(the, DT), (adventure, NN), (of, IN), (the, D...\n",
       "9     [(the, DT), (adventure, NN), (of, IN), (the, D...\n",
       "10    [(the, DT), (adventure, NN), (of, IN), (the, D...\n",
       "11    [(the, DT), (adventure, NN), (of, IN), (the, D...\n",
       "12    [(the, DT), (adventure, NN), (of, IN), (the, D...\n",
       "Name: hikayeler, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b09e2289-c30c-4142-835d-05337dcfdc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumle = \"R and Python are useful data science tools for the new or old data scientists who eager to do efficent data science task\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c09a775-6da6-4a07-bdb9-062b2e31112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = TextBlob(cumle).tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18a1a5a5-9f2a-4310-aa60-09cee419345d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('R', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Python', 'NNP'),\n",
       " ('are', 'VBP'),\n",
       " ('useful', 'JJ'),\n",
       " ('data', 'NNS'),\n",
       " ('science', 'NN'),\n",
       " ('tools', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('or', 'CC'),\n",
       " ('old', 'JJ'),\n",
       " ('data', 'NNS'),\n",
       " ('scientists', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('eager', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('do', 'VB'),\n",
       " ('efficent', 'JJ'),\n",
       " ('data', 'NNS'),\n",
       " ('science', 'NN'),\n",
       " ('task', 'NN')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8af0590-a951-4f97-a2ac-ac6381943e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_exp = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "rp = nltk.RegexpParser(reg_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0f69920-fd10-47d2-a1ec-cf16f1e06913",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonuclar = rp.parse(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37840c8c-24bf-471d-93f4-61d048da299d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The Ghostscript executable isn't found.\n",
      "See http://web.mit.edu/ghostscript/www/Install.htm\n",
      "If you're using a Mac, you can try installing\n",
      "https://docs.brew.sh/Installation then `brew install ghostscript`\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/nltk/tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    813\u001b[0m                     [\n\u001b[0;32m--> 814\u001b[0;31m                         find_binary(\n\u001b[0m\u001b[1;32m    815\u001b[0m                             \u001b[0;34m\"gs\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/nltk/internals.py\u001b[0m in \u001b[0;36mfind_binary\u001b[0;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[1;32m    686\u001b[0m ):\n\u001b[0;32m--> 687\u001b[0;31m     return next(\n\u001b[0m\u001b[1;32m    688\u001b[0m         find_binary_iter(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/nltk/internals.py\u001b[0m in \u001b[0;36mfind_binary_iter\u001b[0;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \"\"\"\n\u001b[0;32m--> 673\u001b[0;31m     yield from find_file_iter(\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0mpath_to_bin\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/nltk/internals.py\u001b[0m in \u001b[0;36mfind_file_iter\u001b[0;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n\\n{div}\\n{msg}\\n{div}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration parameters or set the PATH environment variable.\n===========================================================================",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/nltk/tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m                 )\n\u001b[1;32m    832\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_error_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [('R', 'NNP'), ('and', 'CC'), ('Python', 'NNP'), ('are', 'VBP'), ('useful', 'JJ'), ('data', 'NNS'), Tree('NP', [('science', 'NN')]), ('tools', 'NNS'), ('for', 'IN'), ('the', 'DT'), ('new', 'JJ'), ('or', 'CC'), ('old', 'JJ'), ('data', 'NNS'), ('scientists', 'NNS'), ('who', 'WP'), ('eager', 'VBP'), ('to', 'TO'), ('do', 'VB'), ('efficent', 'JJ'), ('data', 'NNS'), Tree('NP', [('science', 'NN')]), Tree('NP', [('task', 'NN')])])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonuclar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7ec3e96-55eb-42ad-8c35-7f57bba6d552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  R/NNP\n",
      "  and/CC\n",
      "  Python/NNP\n",
      "  are/VBP\n",
      "  useful/JJ\n",
      "  data/NNS\n",
      "  (NP science/NN)\n",
      "  tools/NNS\n",
      "  for/IN\n",
      "  the/DT\n",
      "  new/JJ\n",
      "  or/CC\n",
      "  old/JJ\n",
      "  data/NNS\n",
      "  scientists/NNS\n",
      "  who/WP\n",
      "  eager/VBP\n",
      "  to/TO\n",
      "  do/VB\n",
      "  efficent/JJ\n",
      "  data/NNS\n",
      "  (NP science/NN)\n",
      "  (NP task/NN))\n"
     ]
    }
   ],
   "source": [
    "print(sonuclar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34f8a806-593b-4f64-bdf4-060d185f5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sonuclar.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf86137-a054-4c07-8e55-e2c499e381a5",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ee2af50-109d-4aff-ba77-2b790d9a4737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/sametsengun/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/sametsengun/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9c8a9e3-d3ec-4598-9349-cfbca8ed73ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE Hadley/NNP)\n",
      "  is/VBZ\n",
      "  creative/JJ\n",
      "  people/NNS\n",
      "  who/WP\n",
      "  work/VBP\n",
      "  for/IN\n",
      "  (ORGANIZATION R/NNP Studio/NNP)\n",
      "  AND/CC\n",
      "  he/PRP\n",
      "  attented/VBD\n",
      "  conference/NN\n",
      "  at/IN\n",
      "  (ORGANIZATION Newyork/NNP)\n",
      "  last/JJ\n",
      "  year/NN)\n"
     ]
    }
   ],
   "source": [
    "cumle = \"Hadley is creative people who work for R Studio AND he attented conference at Newyork last year\"\n",
    "print(ne_chunk(pos_tag(word_tokenize(cumle))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35ceff6-ad8c-47bc-bffa-a54c565c603c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
